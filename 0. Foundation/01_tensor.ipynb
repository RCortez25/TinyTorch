{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPHqjThzHdwS3yX0h9khI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RCortez25/TinyTorch/blob/main/0.%20Foundation/01_tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TaJdgFh4bNJk"
      },
      "outputs": [],
      "source": [
        "#| default_exp core.tensor\n",
        "#| export\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Constants for memory calculations\n",
        "BYTES_PER_FLOAT32 = 4  # Standard float32 size in bytes\n",
        "KB_TO_BYTES = 1024  # Kilobytes to bytes conversion\n",
        "MB_TO_BYTES = 1024 * 1024  # Megabytes to bytes conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor class"
      ],
      "metadata": {
        "id": "TGoGBOE6ar78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "class Tensor:\n",
        "    \"\"\"Tensor - the foundation of machine learning computation.\n",
        "\n",
        "    This class provides the core data structure for all ML operations:\n",
        "    - data: The actual numerical values (NumPy array)\n",
        "    - shape: Dimensions of the tensor\n",
        "    - size: Total number of elements\n",
        "    - dtype: Data type (float32)\n",
        "\n",
        "    All arithmetic, matrix, and shape operations are built on this foundation.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        \"\"\"Create a new tensor from data.\"\"\"\n",
        "        self.data = np.array(data, dtype=np.float32)\n",
        "        self.shape = self.data.shape\n",
        "        self.size = self.data.size\n",
        "        self.dtype = self.data.dtype\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"String representation for debugging\"\n",
        "        return f\"Tensor(data={self.data}, shape={self.shape})\"\n",
        "\n",
        "    def __str__(self):\n",
        "        \"String representation\"\n",
        "        return f\"Tensor({self.data})\"\n",
        "\n",
        "    def numpy(self):\n",
        "        \"Return the NumPy array\"\n",
        "        return self.data\n",
        "\n",
        "    def memory_footprint(self):\n",
        "        \"\"\"Calculate exact memory usage in bytes.\n",
        "\n",
        "        Systems Concept: Understanding memory footprint is fundamental to ML systems.\n",
        "        Before running any operation, engineers should know how much memory it requires.\n",
        "\n",
        "        Returns:\n",
        "            int: Memory usage in bytes (e.g., 1000x1000 float32 = 4MB)\n",
        "        \"\"\"\n",
        "        return self.data.nbytes\n",
        "\n",
        "    def __add__(self, other):\n",
        "        \"\"\"Add two tensors element-wise with broadcasting support.\"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data + other.data)\n",
        "        return self.data + other\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        \"\"\"Subtract two tensors element-wise.\"\"\"\n",
        "\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data - other.data)\n",
        "        return self.data - other\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        \"\"\"Multiply two tensors element-wise (NOT matrix multiplication).\"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data * other.data)\n",
        "        return self.data * other\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        \"\"\"Divide two tensors element-wise.\"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data / other.data)\n",
        "        return Tensor(self.data / other)\n",
        "\n",
        "    def matmul(self, other):\n",
        "        \"\"\"Matrix multiplication of two tensors.\"\"\"\n",
        "        if not isinstance(other, Tensor):\n",
        "            raise TypeError(\"Both elements must be tensors\")\n",
        "        if other.data.ndim == 0:\n",
        "            return Tensor(self * other)\n",
        "        if other.data.ndim == 1:\n",
        "            return Tensor(np.matmul(self.data, other.data))\n",
        "        if not self.shape[-1] == other.shape[-2]:\n",
        "            raise ValueError(f\"Inner dimensions must match. {self.shape[-1]} â‰  {other.shape[-2]}\")\n",
        "        if self.data.shape == (2,2):\n",
        "            lst = []\n",
        "            for i in range(2):\n",
        "                for j in range(2):\n",
        "                    result = np.dot(self.data[i,:],other.data[:,j])\n",
        "                    lst.append(result)\n",
        "            return Tensor(np.array(lst).reshape(2,2))\n",
        "        return Tensor(np.matmul(self.data, other.data))\n",
        "\n",
        "    def __matmul__(self, other):\n",
        "        \"\"\"Enable @ operator for matrix multiplication.\"\"\"\n",
        "        return self.matmul(other)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"Enable indexing and slicing operations on Tensors.\"\"\"\n",
        "        return Tensor(np.array(self.data[key]))\n",
        "\n",
        "    def reshape(self, *shape):\n",
        "        \"\"\"Reshape tensor to new dimensions.\n",
        "        - For -1: unknown_dim = self.size // known_size in the tuple\n",
        "        \"\"\"\n",
        "        if isinstance(shape[0], (tuple, list)):\n",
        "            shape = shape[0]\n",
        "        if shape[-1] == -1:\n",
        "            unknown_dim = self.size // shape[0]\n",
        "            shape = (shape[0],unknown_dim)\n",
        "        if self.data.size != np.prod(shape):\n",
        "            raise ValueError(f\"Total elements must match. {self.data.size} â‰  {np.prod(shape)}\")\n",
        "        return Tensor(self.data.reshape(shape))\n",
        "\n",
        "    def transpose(self, dim0=None, dim1=None):\n",
        "        \"\"\"Transpose tensor dimensions.\"\"\"\n",
        "        axes = list(range(len(self.shape)))\n",
        "        if len(axes) == 1:\n",
        "            return self\n",
        "        if dim0 is None and dim1 is None:\n",
        "            axes[-2], axes[-1] = axes[-1], axes[-2]\n",
        "            return Tensor(np.transpose(self.data, axes))\n",
        "        axes[dim0], axes[dim1] = axes[dim1], axes[dim0]\n",
        "        return Tensor(np.transpose(self.data, axes))\n",
        "\n",
        "    def sum(self, axis=None, keepdims=False):\n",
        "        \"\"\"Sum tensor along specified axis.\"\"\"\n",
        "        return Tensor(np.sum(self.data, axis=axis, keepdims=keepdims))\n",
        "\n",
        "    def mean(self, axis=None, keepdims=False):\n",
        "        \"\"\"Compute mean of tensor along specified axis.\"\"\"\n",
        "        result = np.mean(self.data, axis=axis, keepdims=keepdims)\n",
        "        return Tensor(result)\n",
        "\n",
        "    def max(self, axis=None, keepdims=False):\n",
        "        \"\"\"Find maximum values along specified axis.\"\"\"\n",
        "        result = np.max(self.data, axis=axis, keepdims=keepdims)\n",
        "        return Tensor(result)"
      ],
      "metadata": {
        "id": "i4z_D0m4bXEo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### TESTS\n",
        "data = Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "\n",
        "# Reshape to 3D tensor (simulating batch processing)\n",
        "tensor_3d = data.reshape(2, 2, 3)  # (batch=2, height=2, width=3)\n",
        "assert tensor_3d.shape == (2, 2, 3)\n",
        "print(tensor_3d.shape)\n",
        "# Transpose for different operations\n",
        "transposed = tensor_3d.transpose()  # Should transpose last two dims\n",
        "transposed.shape\n",
        "assert transposed.shape == (2, 3, 2)\n",
        "#################### TESTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_fMzoqa0mG4",
        "outputId": "f10ec0c5-0d90-433c-c1f7-204b7f1f9249"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit tests"
      ],
      "metadata": {
        "id": "_hhk0dhgax1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_reduction_operations():\n",
        "    \"\"\"ðŸ§ª Test reduction operations.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Reduction Operations...\")\n",
        "\n",
        "    matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
        "\n",
        "    # Test sum all elements (common for loss computation)\n",
        "    total = matrix.sum()\n",
        "    assert total.data == 21.0  # 1+2+3+4+5+6\n",
        "    assert total.shape == ()   # Scalar result\n",
        "\n",
        "    # Test sum along axis 0 (columns) - batch dimension reduction\n",
        "    col_sum = matrix.sum(axis=0)\n",
        "    expected_col = np.array([5, 7, 9], dtype=np.float32)  # [1+4, 2+5, 3+6]\n",
        "    assert np.array_equal(col_sum.data, expected_col)\n",
        "    assert col_sum.shape == (3,)\n",
        "\n",
        "    # Test sum along axis 1 (rows) - feature dimension reduction\n",
        "    row_sum = matrix.sum(axis=1)\n",
        "    expected_row = np.array([6, 15], dtype=np.float32)  # [1+2+3, 4+5+6]\n",
        "    assert np.array_equal(row_sum.data, expected_row)\n",
        "    assert row_sum.shape == (2,)\n",
        "\n",
        "    # Test mean (average loss computation)\n",
        "    avg = matrix.mean()\n",
        "    assert np.isclose(avg.data, 3.5)  # 21/6\n",
        "    assert avg.shape == ()\n",
        "\n",
        "    # Test mean along axis (batch normalization pattern)\n",
        "    col_mean = matrix.mean(axis=0)\n",
        "    expected_mean = np.array([2.5, 3.5, 4.5], dtype=np.float32)  # [5/2, 7/2, 9/2]\n",
        "    assert np.allclose(col_mean.data, expected_mean)\n",
        "\n",
        "    # Test max (finding best predictions)\n",
        "    maximum = matrix.max()\n",
        "    assert maximum.data == 6.0\n",
        "    assert maximum.shape == ()\n",
        "\n",
        "    # Test max along axis (argmax-like operation)\n",
        "    row_max = matrix.max(axis=1)\n",
        "    expected_max = np.array([3, 6], dtype=np.float32)  # [max(1,2,3), max(4,5,6)]\n",
        "    assert np.array_equal(row_max.data, expected_max)\n",
        "\n",
        "    # Test keepdims (important for broadcasting)\n",
        "    sum_keepdims = matrix.sum(axis=1, keepdims=True)\n",
        "    assert sum_keepdims.shape == (2, 1)  # Maintains 2D shape\n",
        "    expected_keepdims = np.array([[6], [15]], dtype=np.float32)\n",
        "    assert np.array_equal(sum_keepdims.data, expected_keepdims)\n",
        "\n",
        "    # Test 3D reduction (simulating global average pooling)\n",
        "    tensor_3d = Tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # (2, 2, 2)\n",
        "    spatial_mean = tensor_3d.mean(axis=(1, 2))  # Average across spatial dimensions\n",
        "    assert spatial_mean.shape == (2,)  # One value per batch item\n",
        "\n",
        "    print(\"âœ… Reduction operations work correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_reduction_operations()"
      ],
      "metadata": {
        "id": "8mhw8kgQaxza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6829db3a-c7ed-4dea-d25d-271360b6ecd7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Reduction Operations...\n",
            "âœ… Reduction operations work correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_shape_manipulation():\n",
        "    \"\"\"ðŸ§ª Test reshape and transpose operations.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Shape Manipulation...\")\n",
        "\n",
        "    # Test basic reshape (flatten â†’ matrix)\n",
        "    tensor = Tensor([1, 2, 3, 4, 5, 6])  # Shape: (6,)\n",
        "    reshaped = tensor.reshape(2, 3)      # Shape: (2, 3)\n",
        "    assert reshaped.shape == (2, 3)\n",
        "    expected = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n",
        "    assert np.array_equal(reshaped.data, expected)\n",
        "\n",
        "    # Test reshape with tuple (alternative calling style)\n",
        "    reshaped2 = tensor.reshape((3, 2))   # Shape: (3, 2)\n",
        "    assert reshaped2.shape == (3, 2)\n",
        "    expected2 = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float32)\n",
        "    assert np.array_equal(reshaped2.data, expected2)\n",
        "\n",
        "    # Test reshape with -1 (automatic dimension inference)\n",
        "    auto_reshaped = tensor.reshape(2, -1)  # Should infer -1 as 3\n",
        "    assert auto_reshaped.shape == (2, 3)\n",
        "\n",
        "    # Test reshape validation - should raise error for incompatible sizes\n",
        "    try:\n",
        "        tensor.reshape(2, 2)  # 6 elements can't fit in 2Ã—2=4\n",
        "        assert False, \"Should have raised ValueError\"\n",
        "    except ValueError as e:\n",
        "        assert \"Total elements must match\" in str(e)\n",
        "        assert \"6 â‰  4\" in str(e)\n",
        "\n",
        "    # Test matrix transpose (most common case)\n",
        "    matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # (2, 3)\n",
        "    transposed = matrix.transpose()          # (3, 2)\n",
        "    assert transposed.shape == (3, 2)\n",
        "    expected = np.array([[1, 4], [2, 5], [3, 6]], dtype=np.float32)\n",
        "    assert np.array_equal(transposed.data, expected)\n",
        "\n",
        "    # Test 1D transpose (should be identity)\n",
        "    vector = Tensor([1, 2, 3])\n",
        "    vector_t = vector.transpose()\n",
        "    assert np.array_equal(vector.data, vector_t.data)\n",
        "\n",
        "    # Test specific dimension transpose\n",
        "    tensor_3d = Tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # (2, 2, 2)\n",
        "    swapped = tensor_3d.transpose(0, 2)  # Swap first and last dimensions\n",
        "    assert swapped.shape == (2, 2, 2)  # Same shape but data rearranged\n",
        "\n",
        "    # Test neural network reshape pattern (flatten for MLP)\n",
        "    batch_images = Tensor(np.random.rand(2, 3, 4))  # (batch=2, height=3, width=4)\n",
        "    flattened = batch_images.reshape(2, -1)  # (batch=2, features=12)\n",
        "    assert flattened.shape == (2, 12)\n",
        "\n",
        "    print(\"âœ… Shape manipulation works correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_shape_manipulation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEdOB9vb8cAi",
        "outputId": "17301e7e-28bd-4e8b-9eb2-cc778b01f722"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Shape Manipulation...\n",
            "âœ… Shape manipulation works correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_matrix_multiplication():\n",
        "    \"\"\"ðŸ§ª Test matrix multiplication operations.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Matrix Multiplication...\")\n",
        "\n",
        "    # Test 2Ã—2 matrix multiplication (basic case)\n",
        "    a = Tensor([[1, 2], [3, 4]])  # 2Ã—2\n",
        "    b = Tensor([[5, 6], [7, 8]])  # 2Ã—2\n",
        "    result = a.matmul(b)\n",
        "    # Expected: [[1Ã—5+2Ã—7, 1Ã—6+2Ã—8], [3Ã—5+4Ã—7, 3Ã—6+4Ã—8]] = [[19, 22], [43, 50]]\n",
        "    expected = np.array([[19, 22], [43, 50]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test rectangular matrices (common in neural networks)\n",
        "    c = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3 (like batch_size=2, features=3)\n",
        "    d = Tensor([[7, 8], [9, 10], [11, 12]])  # 3Ã—2 (like features=3, outputs=2)\n",
        "    result = c.matmul(d)\n",
        "    # Expected: [[1Ã—7+2Ã—9+3Ã—11, 1Ã—8+2Ã—10+3Ã—12], [4Ã—7+5Ã—9+6Ã—11, 4Ã—8+5Ã—10+6Ã—12]]\n",
        "    expected = np.array([[58, 64], [139, 154]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test matrix-vector multiplication (common in forward pass)\n",
        "    matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3\n",
        "    vector = Tensor([1, 2, 3])  # 3Ã—1 (conceptually)\n",
        "    result = matrix.matmul(vector)\n",
        "    # Expected: [1Ã—1+2Ã—2+3Ã—3, 4Ã—1+5Ã—2+6Ã—3] = [14, 32]\n",
        "    expected = np.array([14, 32], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test shape validation - should raise clear error\n",
        "    try:\n",
        "        incompatible_a = Tensor([[1, 2]])     # 1Ã—2\n",
        "        incompatible_b = Tensor([[1], [2], [3]])  # 3Ã—1\n",
        "        incompatible_a.matmul(incompatible_b)  # 1Ã—2 @ 3Ã—1 should fail (2 â‰  3)\n",
        "        assert False, \"Should have raised ValueError for incompatible shapes\"\n",
        "    except ValueError as e:\n",
        "        assert \"Inner dimensions must match\" in str(e)\n",
        "        assert \"2 â‰  3\" in str(e)  # Should show specific dimensions\n",
        "\n",
        "    print(\"âœ… Matrix multiplication works correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_matrix_multiplication()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOrSZT355FFk",
        "outputId": "fff457b7-3bf6-4713-edfd-8e34874231e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Matrix Multiplication...\n",
            "âœ… Matrix multiplication works correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_arithmetic_operations():\n",
        "    \"\"\"ðŸ§ª Test arithmetic operations with broadcasting.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Arithmetic Operations...\")\n",
        "\n",
        "    # Test tensor + tensor\n",
        "    a = Tensor([1, 2, 3])\n",
        "    b = Tensor([4, 5, 6])\n",
        "    result = a + b\n",
        "    assert np.array_equal(result.data, np.array([5, 7, 9], dtype=np.float32))\n",
        "\n",
        "    # Test tensor + scalar (very common in ML)\n",
        "    result = a + 10\n",
        "    assert np.array_equal(result.data, np.array([11, 12, 13], dtype=np.float32))\n",
        "\n",
        "    # Test broadcasting with different shapes (matrix + vector)\n",
        "    matrix = Tensor([[1, 2], [3, 4]])\n",
        "    vector = Tensor([10, 20])\n",
        "    result = matrix + vector\n",
        "    expected = np.array([[11, 22], [13, 24]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test subtraction (data centering)\n",
        "    result = b - a\n",
        "    assert np.array_equal(result.data, np.array([3, 3, 3], dtype=np.float32))\n",
        "\n",
        "    # Test multiplication (scaling)\n",
        "    result = a * 2\n",
        "    assert np.array_equal(result.data, np.array([2, 4, 6], dtype=np.float32))\n",
        "\n",
        "    # Test division (normalization)\n",
        "    result = b / 2\n",
        "    assert np.array_equal(result.data, np.array([2.0, 2.5, 3.0], dtype=np.float32))\n",
        "\n",
        "    # Test chaining operations (common in ML pipelines)\n",
        "    normalized = (a - 2) / 2  # Center and scale\n",
        "    expected = np.array([-0.5, 0.0, 0.5], dtype=np.float32)\n",
        "    assert np.allclose(normalized.data, expected)\n",
        "\n",
        "    print(\"âœ… Arithmetic operations work correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_arithmetic_operations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zu5Xyaa0iOv",
        "outputId": "8bf55d2f-8368-4772-e320-25461ba41661"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Arithmetic Operations...\n",
            "âœ… Arithmetic operations work correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_tensor_creation():\n",
        "    \"\"\"ðŸ§ª Test Tensor creation with various data types.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Tensor Creation...\")\n",
        "\n",
        "    # Test scalar creation\n",
        "    scalar = Tensor(5.0)\n",
        "    assert scalar.data == 5.0\n",
        "    assert scalar.shape == ()\n",
        "    assert scalar.size == 1\n",
        "    assert scalar.dtype == np.float32\n",
        "\n",
        "    # Test vector creation\n",
        "    vector = Tensor([1, 2, 3])\n",
        "    assert np.array_equal(vector.data, np.array([1, 2, 3], dtype=np.float32))\n",
        "    assert vector.shape == (3,)\n",
        "    assert vector.size == 3\n",
        "\n",
        "    # Test matrix creation\n",
        "    matrix = Tensor([[1, 2], [3, 4]])\n",
        "    assert np.array_equal(matrix.data, np.array([[1, 2], [3, 4]], dtype=np.float32))\n",
        "    assert matrix.shape == (2, 2)\n",
        "    assert matrix.size == 4\n",
        "\n",
        "    # Test 3D tensor creation\n",
        "    tensor_3d = Tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "    assert tensor_3d.shape == (2, 2, 2)\n",
        "    assert tensor_3d.size == 8\n",
        "\n",
        "    print(\"âœ… Tensor creation works correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_tensor_creation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzC6z6KXhS_K",
        "outputId": "74ab6a72-ddd6-4191-a34f-7c1acdc91158"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Tensor Creation...\n",
            "âœ… Tensor creation works correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory analysis"
      ],
      "metadata": {
        "id": "FjQxxSfdbAFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_memory_layout():\n",
        "    \"\"\"ðŸ“Š Demonstrate cache effects with row vs column access patterns.\"\"\"\n",
        "    print(\"ðŸ“Š Analyzing Memory Access Patterns...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create a moderately-sized matrix (large enough to show cache effects)\n",
        "    size = 2000\n",
        "    matrix = Tensor(np.random.rand(size, size))\n",
        "\n",
        "    import time\n",
        "\n",
        "    print(f\"\\nTesting with {size}Ã—{size} matrix ({matrix.size * BYTES_PER_FLOAT32 / MB_TO_BYTES:.1f} MB)\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Test 1: Row-wise access (cache-friendly)\n",
        "    # Memory layout: [row0][row1][row2]... stored contiguously\n",
        "    print(\"\\nðŸ”¬ Test 1: Row-wise Access (Cache-Friendly)\")\n",
        "    start = time.time()\n",
        "    row_sums = []\n",
        "    for i in range(size):\n",
        "        row_sum = matrix.data[i, :].sum()  # Access entire row sequentially\n",
        "        row_sums.append(row_sum)\n",
        "    row_time = time.time() - start\n",
        "    print(f\"   Time: {row_time*1000:.1f}ms\")\n",
        "    print(f\"   Access pattern: Sequential (follows memory layout)\")\n",
        "\n",
        "    # Test 2: Column-wise access (cache-unfriendly)\n",
        "    # Must jump between rows, poor spatial locality\n",
        "    print(\"\\nðŸ”¬ Test 2: Column-wise Access (Cache-Unfriendly)\")\n",
        "    start = time.time()\n",
        "    col_sums = []\n",
        "    for j in range(size):\n",
        "        col_sum = matrix.data[:, j].sum()  # Access entire column with large strides\n",
        "        col_sums.append(col_sum)\n",
        "    col_time = time.time() - start\n",
        "    print(f\"   Time: {col_time*1000:.1f}ms\")\n",
        "    print(f\"   Access pattern: Strided (jumps {size * BYTES_PER_FLOAT32} bytes per element)\")\n",
        "\n",
        "    # Calculate slowdown\n",
        "    slowdown = col_time / row_time\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"ðŸ“Š PERFORMANCE IMPACT:\")\n",
        "    print(f\"   Slowdown factor: {slowdown:.2f}Ã— ({col_time/row_time:.1f}Ã— slower)\")\n",
        "    print(f\"   Cache misses cause {(slowdown-1)*100:.0f}% performance loss\")\n",
        "\n",
        "    # Educational insights\n",
        "    print(\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
        "    print(f\"   1. Memory layout matters: Row-major (C-style) storage is sequential\")\n",
        "    print(f\"   2. Cache lines are ~64 bytes: Row access loads nearby elements \\\"for free\\\"\")\n",
        "    print(f\"   3. Column access misses cache: Must reload from DRAM every time\")\n",
        "    print(f\"   4. This is O(n) algorithm but {slowdown:.1f}Ã— different wall-clock time!\")\n",
        "\n",
        "    print(\"\\nðŸš€ REAL-WORLD IMPLICATIONS:\")\n",
        "    print(f\"   â€¢ CNNs use NCHW format (channels sequential) for cache efficiency\")\n",
        "    print(f\"   â€¢ Matrix multiplication optimized with blocking (tile into cache-sized chunks)\")\n",
        "    print(f\"   â€¢ Transpose is expensive ({slowdown:.1f}Ã—) because it changes memory layout\")\n",
        "    print(f\"   â€¢ This is why GPU frameworks obsess over memory coalescing\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Run the systems analysis\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_memory_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehAghvvCjqH3",
        "outputId": "3bc41f29-1c7c-4d7a-f0ef-3cdfc15e5c4f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Analyzing Memory Access Patterns...\n",
            "============================================================\n",
            "\n",
            "Testing with 2000Ã—2000 matrix (15.3 MB)\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸ”¬ Test 1: Row-wise Access (Cache-Friendly)\n",
            "   Time: 7.7ms\n",
            "   Access pattern: Sequential (follows memory layout)\n",
            "\n",
            "ðŸ”¬ Test 2: Column-wise Access (Cache-Unfriendly)\n",
            "   Time: 12.5ms\n",
            "   Access pattern: Strided (jumps 8000 bytes per element)\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š PERFORMANCE IMPACT:\n",
            "   Slowdown factor: 1.63Ã— (1.6Ã— slower)\n",
            "   Cache misses cause 63% performance loss\n",
            "\n",
            "ðŸ’¡ KEY INSIGHTS:\n",
            "   1. Memory layout matters: Row-major (C-style) storage is sequential\n",
            "   2. Cache lines are ~64 bytes: Row access loads nearby elements \"for free\"\n",
            "   3. Column access misses cache: Must reload from DRAM every time\n",
            "   4. This is O(n) algorithm but 1.6Ã— different wall-clock time!\n",
            "\n",
            "ðŸš€ REAL-WORLD IMPLICATIONS:\n",
            "   â€¢ CNNs use NCHW format (channels sequential) for cache efficiency\n",
            "   â€¢ Matrix multiplication optimized with blocking (tile into cache-sized chunks)\n",
            "   â€¢ Transpose is expensive (1.6Ã—) because it changes memory layout\n",
            "   â€¢ This is why GPU frameworks obsess over memory coalescing\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module integration test"
      ],
      "metadata": {
        "id": "xizKEJkSjwk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_module():\n",
        "    \"\"\"ðŸ§ª Module Test: Complete Integration\n",
        "\n",
        "    Comprehensive test of entire module functionality.\n",
        "\n",
        "    This final test runs before module summary to ensure:\n",
        "    - All unit tests pass\n",
        "    - Functions work together correctly\n",
        "    - Module is ready for integration with TinyTorch\n",
        "    \"\"\"\n",
        "    print(\"ðŸ§ª RUNNING MODULE INTEGRATION TEST\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Run all unit tests\n",
        "    print(\"Running unit tests...\")\n",
        "    test_unit_tensor_creation()\n",
        "    test_unit_arithmetic_operations()\n",
        "    test_unit_matrix_multiplication()\n",
        "    test_unit_shape_manipulation()\n",
        "    test_unit_reduction_operations()\n",
        "\n",
        "    print(\"\\nRunning integration scenarios...\")\n",
        "\n",
        "    # Test realistic neural network computation\n",
        "    print(\"ðŸ§ª Integration Test: Two-Layer Neural Network...\")\n",
        "\n",
        "    # Create input data (2 samples, 3 features)\n",
        "    x = Tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "    # First layer: 3 inputs â†’ 4 hidden units\n",
        "    W1 = Tensor([[0.1, 0.2, 0.3, 0.4],\n",
        "                 [0.5, 0.6, 0.7, 0.8],\n",
        "                 [0.9, 1.0, 1.1, 1.2]])\n",
        "    b1 = Tensor([0.1, 0.2, 0.3, 0.4])\n",
        "\n",
        "    # Forward pass: hidden = xW1 + b1\n",
        "    hidden = x.matmul(W1) + b1\n",
        "    assert hidden.shape == (2, 4), f\"Expected (2, 4), got {hidden.shape}\"\n",
        "\n",
        "    # Second layer: 4 hidden â†’ 2 outputs\n",
        "    W2 = Tensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6], [0.7, 0.8]])\n",
        "    b2 = Tensor([0.1, 0.2])\n",
        "\n",
        "    # Output layer: output = hiddenW2 + b2\n",
        "    output = hidden.matmul(W2) + b2\n",
        "    assert output.shape == (2, 2), f\"Expected (2, 2), got {output.shape}\"\n",
        "\n",
        "    # Verify data flows correctly (no NaN, reasonable values)\n",
        "    assert not np.isnan(output.data).any(), \"Output contains NaN values\"\n",
        "    assert np.isfinite(output.data).all(), \"Output contains infinite values\"\n",
        "\n",
        "    print(\"âœ… Two-layer neural network computation works!\")\n",
        "\n",
        "    # Test complex shape manipulations\n",
        "    print(\"ðŸ§ª Integration Test: Complex Shape Operations...\")\n",
        "    data = Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "\n",
        "    # Reshape to 3D tensor (simulating batch processing)\n",
        "    tensor_3d = data.reshape(2, 2, 3)  # (batch=2, height=2, width=3)\n",
        "    assert tensor_3d.shape == (2, 2, 3)\n",
        "\n",
        "    # Global average pooling simulation\n",
        "    pooled = tensor_3d.mean(axis=(1, 2))  # Average across spatial dimensions\n",
        "    assert pooled.shape == (2,), f\"Expected (2,), got {pooled.shape}\"\n",
        "\n",
        "    # Flatten for MLP\n",
        "    flattened = tensor_3d.reshape(2, -1)  # (batch, features)\n",
        "    assert flattened.shape == (2, 6)\n",
        "\n",
        "    # Transpose for different operations\n",
        "    transposed = tensor_3d.transpose()  # Should transpose last two dims\n",
        "    assert transposed.shape == (2, 3, 2)\n",
        "\n",
        "    print(\"âœ… Complex shape operations work!\")\n",
        "\n",
        "    # Test broadcasting edge cases\n",
        "    print(\"ðŸ§ª Integration Test: Broadcasting Edge Cases...\")\n",
        "\n",
        "    # Scalar broadcasting\n",
        "    scalar = Tensor(5.0)\n",
        "    vector = Tensor([1, 2, 3])\n",
        "    result = scalar + vector  # Should broadcast scalar to vector shape\n",
        "    expected = np.array([6, 7, 8], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Matrix + vector broadcasting\n",
        "    matrix = Tensor([[1, 2], [3, 4]])\n",
        "    vec = Tensor([10, 20])\n",
        "    result = matrix + vec\n",
        "    expected = np.array([[11, 22], [13, 24]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    print(\"âœ… Broadcasting edge cases work!\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ðŸŽ‰ ALL TESTS PASSED! Module ready for export.\")\n",
        "    print(\"Run: tito module complete 01_tensor\")\n",
        "\n",
        "# Run comprehensive module test\n",
        "if __name__ == \"__main__\":\n",
        "    test_module()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7thPO5K2j-H9",
        "outputId": "d641f219-6e53-4c24-f564-c389878f3e12"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª RUNNING MODULE INTEGRATION TEST\n",
            "==================================================\n",
            "Running unit tests...\n",
            "ðŸ§ª Unit Test: Tensor Creation...\n",
            "âœ… Tensor creation works correctly!\n",
            "ðŸ§ª Unit Test: Arithmetic Operations...\n",
            "âœ… Arithmetic operations work correctly!\n",
            "ðŸ§ª Unit Test: Matrix Multiplication...\n",
            "âœ… Matrix multiplication works correctly!\n",
            "ðŸ§ª Unit Test: Shape Manipulation...\n",
            "âœ… Shape manipulation works correctly!\n",
            "ðŸ§ª Unit Test: Reduction Operations...\n",
            "âœ… Reduction operations work correctly!\n",
            "\n",
            "Running integration scenarios...\n",
            "ðŸ§ª Integration Test: Two-Layer Neural Network...\n",
            "âœ… Two-layer neural network computation works!\n",
            "ðŸ§ª Integration Test: Complex Shape Operations...\n",
            "âœ… Complex shape operations work!\n",
            "ðŸ§ª Integration Test: Broadcasting Edge Cases...\n",
            "âœ… Broadcasting edge cases work!\n",
            "\n",
            "==================================================\n",
            "ðŸŽ‰ ALL TESTS PASSED! Module ready for export.\n",
            "Run: tito module complete 01_tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo tensor"
      ],
      "metadata": {
        "id": "8QjD3POYlQM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_tensor():\n",
        "    \"\"\"ðŸŽ¯ See your Tensor work just like NumPy.\"\"\"\n",
        "    print(\"ðŸŽ¯ AHA MOMENT: Your Tensor Works Like NumPy\")\n",
        "    print(\"=\" * 45)\n",
        "\n",
        "    # Create tensors\n",
        "    a = Tensor(np.array([1, 2, 3]))\n",
        "    b = Tensor(np.array([4, 5, 6]))\n",
        "\n",
        "    # Tensor operations\n",
        "    tensor_sum = a + b\n",
        "    tensor_prod = a * b\n",
        "\n",
        "    # NumPy equivalents\n",
        "    np_sum = np.array([1, 2, 3]) + np.array([4, 5, 6])\n",
        "    np_prod = np.array([1, 2, 3]) * np.array([4, 5, 6])\n",
        "\n",
        "    print(f\"Tensor a + b: {tensor_sum.data}\")\n",
        "    print(f\"NumPy  a + b: {np_sum}\")\n",
        "    print(f\"Match: {np.allclose(tensor_sum.data, np_sum)}\")\n",
        "\n",
        "    print(f\"\\nTensor a * b: {tensor_prod.data}\")\n",
        "    print(f\"NumPy  a * b: {np_prod}\")\n",
        "    print(f\"Match: {np.allclose(tensor_prod.data, np_prod)}\")\n",
        "\n",
        "    print(\"\\nâœ¨ Your Tensor is NumPy-compatibleâ€”ready for ML!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_module()\n",
        "    print(\"\\n\")\n",
        "    demo_tensor()"
      ],
      "metadata": {
        "id": "6g_vFtgukAvZ",
        "outputId": "8a594ab1-8910-4819-e043-c8117d8d0528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª RUNNING MODULE INTEGRATION TEST\n",
            "==================================================\n",
            "Running unit tests...\n",
            "ðŸ§ª Unit Test: Tensor Creation...\n",
            "âœ… Tensor creation works correctly!\n",
            "ðŸ§ª Unit Test: Arithmetic Operations...\n",
            "âœ… Arithmetic operations work correctly!\n",
            "ðŸ§ª Unit Test: Matrix Multiplication...\n",
            "âœ… Matrix multiplication works correctly!\n",
            "ðŸ§ª Unit Test: Shape Manipulation...\n",
            "âœ… Shape manipulation works correctly!\n",
            "ðŸ§ª Unit Test: Reduction Operations...\n",
            "âœ… Reduction operations work correctly!\n",
            "\n",
            "Running integration scenarios...\n",
            "ðŸ§ª Integration Test: Two-Layer Neural Network...\n",
            "âœ… Two-layer neural network computation works!\n",
            "ðŸ§ª Integration Test: Complex Shape Operations...\n",
            "âœ… Complex shape operations work!\n",
            "ðŸ§ª Integration Test: Broadcasting Edge Cases...\n",
            "âœ… Broadcasting edge cases work!\n",
            "\n",
            "==================================================\n",
            "ðŸŽ‰ ALL TESTS PASSED! Module ready for export.\n",
            "Run: tito module complete 01_tensor\n",
            "\n",
            "\n",
            "ðŸŽ¯ AHA MOMENT: Your Tensor Works Like NumPy\n",
            "=============================================\n",
            "Tensor a + b: [5. 7. 9.]\n",
            "NumPy  a + b: [5 7 9]\n",
            "Match: True\n",
            "\n",
            "Tensor a * b: [ 4. 10. 18.]\n",
            "NumPy  a * b: [ 4 10 18]\n",
            "Match: True\n",
            "\n",
            "âœ¨ Your Tensor is NumPy-compatibleâ€”ready for ML!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i4iCkQ2mlToT"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}