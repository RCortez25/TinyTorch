{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM99R3CQtPf28DuqI6uhUq1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaJdgFh4bNJk"
      },
      "outputs": [],
      "source": [
        "#| default_exp core.tensor\n",
        "#| export\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Constants for memory calculations\n",
        "BYTES_PER_FLOAT32 = 4  # Standard float32 size in bytes\n",
        "KB_TO_BYTES = 1024  # Kilobytes to bytes conversion\n",
        "MB_TO_BYTES = 1024 * 1024  # Megabytes to bytes conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor class"
      ],
      "metadata": {
        "id": "TGoGBOE6ar78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "class Tensor:\n",
        "    \"\"\"Educational tensor - the foundation of machine learning computation.\n",
        "\n",
        "    This class provides the core data structure for all ML operations:\n",
        "    - data: The actual numerical values (NumPy array)\n",
        "    - shape: Dimensions of the tensor\n",
        "    - size: Total number of elements\n",
        "    - dtype: Data type (float32)\n",
        "\n",
        "    All arithmetic, matrix, and shape operations are built on this foundation.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        \"\"\"Create a new tensor from data.\n",
        "\n",
        "        TODO: Initialize a Tensor by wrapping data in a NumPy array and setting attributes.\n",
        "\n",
        "        APPROACH:\n",
        "        1. Convert data to NumPy array with dtype=float32\n",
        "        2. Store the array as self.data\n",
        "        3. Set self.shape from the array's shape\n",
        "        4. Set self.size from the array's size\n",
        "        5. Set self.dtype from the array's dtype\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> t = Tensor([1, 2, 3])\n",
        "        >>> print(t.shape)\n",
        "        (3,)\n",
        "        >>> print(t.size)\n",
        "        3\n",
        "\n",
        "        HINT: Use np.array(data, dtype=np.float32) to convert data to NumPy array\n",
        "        \"\"\"\n",
        "        self.data = np.array(data, dtype=np.float32)\n",
        "        self.shape = self.data.shape\n",
        "        self.size = self.data.size\n",
        "        self.dtype = self.data.dtype\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"String representation for debugging\"\n",
        "        return f\"Tensor(data={self.data}, shape={self.shape})\"\n",
        "\n",
        "    def __str__(self):\n",
        "        \"String representation\"\n",
        "        return f\"Tensor({self.data})\"\n",
        "\n",
        "    def numpy(self):\n",
        "        \"Return the NumPy array\"\n",
        "        return self.data\n",
        "\n",
        "    def memory_footprint(self):\n",
        "        \"\"\"Calculate exact memory usage in bytes.\n",
        "\n",
        "        Systems Concept: Understanding memory footprint is fundamental to ML systems.\n",
        "        Before running any operation, engineers should know how much memory it requires.\n",
        "\n",
        "        Returns:\n",
        "            int: Memory usage in bytes (e.g., 1000x1000 float32 = 4MB)\n",
        "        \"\"\"\n",
        "        return self.data.nbytes\n",
        "\n",
        "    def __add__(self, other):\n",
        "        \"\"\"Add two tensors element-wise with broadcasting support.\n",
        "\n",
        "        TODO: Implement element-wise addition that works with both Tensors and scalars.\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor (use isinstance)\n",
        "        2. If Tensor: add self.data + other.data\n",
        "        3. If scalar: add self.data + other (broadcasting)\n",
        "        4. Wrap result in new Tensor\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([1, 2, 3])\n",
        "        >>> b = Tensor([4, 5, 6])\n",
        "        >>> c = a + b\n",
        "        >>> print(c.data)\n",
        "        [5. 7. 9.]\n",
        "\n",
        "        HINT: NumPy's + operator handles broadcasting automatically\n",
        "        \"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data + other.data)\n",
        "        return self.data + other\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        \"\"\"Subtract two tensors element-wise.\n",
        "\n",
        "        TODO: Implement element-wise subtraction (same pattern as __add__).\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor\n",
        "        2. If Tensor: subtract self.data - other.data\n",
        "        3. If scalar: subtract self.data - other\n",
        "        4. Return new Tensor with result\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([5, 7, 9])\n",
        "        >>> b = Tensor([1, 2, 3])\n",
        "        >>> c = a - b\n",
        "        >>> print(c.data)\n",
        "        [4. 5. 6.]\n",
        "\n",
        "        HINT: Follow the same pattern as __add__ but with subtraction\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data - other.data)\n",
        "        return self.data - other\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        \"\"\"Multiply two tensors element-wise (NOT matrix multiplication).\n",
        "\n",
        "        TODO: Implement element-wise multiplication (same pattern as __add__).\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor\n",
        "        2. If Tensor: multiply self.data * other.data\n",
        "        3. If scalar: multiply self.data * other\n",
        "        4. Return new Tensor with result\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([1, 2, 3])\n",
        "        >>> b = Tensor([4, 5, 6])\n",
        "        >>> c = a * b\n",
        "        >>> print(c.data)\n",
        "        [ 4. 10. 18.]\n",
        "\n",
        "        HINT: Element-wise multiplication is *, not matrix multiplication (@)\n",
        "        \"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data * other.data)\n",
        "        return self.data * other\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        \"\"\"Divide two tensors element-wise.\n",
        "\n",
        "        TODO: Implement element-wise division (same pattern as __add__).\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor\n",
        "        2. If Tensor: divide self.data / other.data\n",
        "        3. If scalar: divide self.data / other\n",
        "        4. Return new Tensor with result\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([4, 6, 8])\n",
        "        >>> b = Tensor([2, 2, 2])\n",
        "        >>> c = a / b\n",
        "        >>> print(c.data)\n",
        "        [2. 3. 4.]\n",
        "\n",
        "        HINT: Division creates float results automatically due to float32 dtype\n",
        "        \"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data / other.data)\n",
        "        return Tensor(self.data / other)\n",
        "\n",
        "    def matmul(self, other):\n",
        "        \"\"\"Matrix multiplication of two tensors.\n",
        "\n",
        "        TODO: Implement matrix multiplication with shape validation.\n",
        "\n",
        "        APPROACH:\n",
        "        1. Validate other is a Tensor (raise TypeError if not)\n",
        "        2. Check for scalar cases (0D tensors) - use element-wise multiply\n",
        "        3. For 2D+ matrices: validate inner dimensions match (shape[-1] == shape[-2])\n",
        "        4. For 2D matrices: use explicit nested loops (educational)\n",
        "        5. For batched (3D+): use np.matmul for correctness\n",
        "        6. Return result wrapped in Tensor\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([[1, 2], [3, 4]])  # 2Ã—2\n",
        "        >>> b = Tensor([[5, 6], [7, 8]])  # 2Ã—2\n",
        "        >>> c = a.matmul(b)\n",
        "        >>> print(c.data)\n",
        "        [[19. 22.]\n",
        "         [43. 50.]]\n",
        "\n",
        "        HINTS:\n",
        "        - Inner dimensions must match: (M, K) @ (K, N) = (M, N)\n",
        "        - For 2D case: use np.dot(a[i, :], b[:, j]) for each output element\n",
        "        - Raise ValueError with clear message if shapes incompatible\n",
        "        \"\"\"\n",
        "        if not isinstance(other, Tensor):\n",
        "            raise TypeError(\"Both elements must be tensors\")\n",
        "        if other.size == 1:\n",
        "            return self * other\n",
        "        if not self.shape[-1] == other.shape[-2]:\n",
        "            raise ValueError(\"Shapes don't match\")\n",
        "        if self.shape == (2,2):\n",
        "            result = []\n",
        "            for i in range(2):\n",
        "                for j in range(2):\n",
        "                    result.append(np.dot[self.data[i,:], other.data[:,j]])\n",
        "            return Tensor()\n",
        "\n"
      ],
      "metadata": {
        "id": "i4z_D0m4bXEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit tests"
      ],
      "metadata": {
        "id": "_hhk0dhgax1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_matrix_multiplication():\n",
        "    \"\"\"ðŸ§ª Test matrix multiplication operations.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Matrix Multiplication...\")\n",
        "\n",
        "    # Test 2Ã—2 matrix multiplication (basic case)\n",
        "    a = Tensor([[1, 2], [3, 4]])  # 2Ã—2\n",
        "    b = Tensor([[5, 6], [7, 8]])  # 2Ã—2\n",
        "    result = a.matmul(b)\n",
        "    # Expected: [[1Ã—5+2Ã—7, 1Ã—6+2Ã—8], [3Ã—5+4Ã—7, 3Ã—6+4Ã—8]] = [[19, 22], [43, 50]]\n",
        "    expected = np.array([[19, 22], [43, 50]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # # Test rectangular matrices (common in neural networks)\n",
        "    # c = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3 (like batch_size=2, features=3)\n",
        "    # d = Tensor([[7, 8], [9, 10], [11, 12]])  # 3Ã—2 (like features=3, outputs=2)\n",
        "    # result = c.matmul(d)\n",
        "    # # Expected: [[1Ã—7+2Ã—9+3Ã—11, 1Ã—8+2Ã—10+3Ã—12], [4Ã—7+5Ã—9+6Ã—11, 4Ã—8+5Ã—10+6Ã—12]]\n",
        "    # expected = np.array([[58, 64], [139, 154]], dtype=np.float32)\n",
        "    # assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # # Test matrix-vector multiplication (common in forward pass)\n",
        "    # matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3\n",
        "    # vector = Tensor([1, 2, 3])  # 3Ã—1 (conceptually)\n",
        "    # result = matrix.matmul(vector)\n",
        "    # # Expected: [1Ã—1+2Ã—2+3Ã—3, 4Ã—1+5Ã—2+6Ã—3] = [14, 32]\n",
        "    # expected = np.array([14, 32], dtype=np.float32)\n",
        "    # assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # # Test shape validation - should raise clear error\n",
        "    # try:\n",
        "    #     incompatible_a = Tensor([[1, 2]])     # 1Ã—2\n",
        "    #     incompatible_b = Tensor([[1], [2], [3]])  # 3Ã—1\n",
        "    #     incompatible_a.matmul(incompatible_b)  # 1Ã—2 @ 3Ã—1 should fail (2 â‰  3)\n",
        "    #     assert False, \"Should have raised ValueError for incompatible shapes\"\n",
        "    # except ValueError as e:\n",
        "    #     assert \"Inner dimensions must match\" in str(e)\n",
        "    #     assert \"2 â‰  3\" in str(e)  # Should show specific dimensions\n",
        "\n",
        "    print(\"âœ… Matrix multiplication works correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_matrix_multiplication()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "pOrSZT355FFk",
        "outputId": "85bc105f-9a12-4e23-cfdc-29776012a61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Matrix Multiplication...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'numpy._ArrayFunctionDispatcher' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1562059480.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtest_unit_matrix_multiplication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1562059480.py\u001b[0m in \u001b[0;36mtest_unit_matrix_multiplication\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2Ã—2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2Ã—2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Expected: [[1Ã—5+2Ã—7, 1Ã—6+2Ã—8], [3Ã—5+4Ã—7, 3Ã—6+4Ã—8]] = [[19, 22], [43, 50]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2625852349.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy._ArrayFunctionDispatcher' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_arithmetic_operations():\n",
        "    \"\"\"ðŸ§ª Test arithmetic operations with broadcasting.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Arithmetic Operations...\")\n",
        "\n",
        "    # Test tensor + tensor\n",
        "    a = Tensor([1, 2, 3])\n",
        "    b = Tensor([4, 5, 6])\n",
        "    result = a + b\n",
        "    assert np.array_equal(result.data, np.array([5, 7, 9], dtype=np.float32))\n",
        "\n",
        "    # Test tensor + scalar (very common in ML)\n",
        "    result = a + 10\n",
        "    assert np.array_equal(result.data, np.array([11, 12, 13], dtype=np.float32))\n",
        "\n",
        "    # Test broadcasting with different shapes (matrix + vector)\n",
        "    matrix = Tensor([[1, 2], [3, 4]])\n",
        "    vector = Tensor([10, 20])\n",
        "    result = matrix + vector\n",
        "    expected = np.array([[11, 22], [13, 24]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test subtraction (data centering)\n",
        "    result = b - a\n",
        "    assert np.array_equal(result.data, np.array([3, 3, 3], dtype=np.float32))\n",
        "\n",
        "    # Test multiplication (scaling)\n",
        "    result = a * 2\n",
        "    assert np.array_equal(result.data, np.array([2, 4, 6], dtype=np.float32))\n",
        "\n",
        "    # Test division (normalization)\n",
        "    result = b / 2\n",
        "    assert np.array_equal(result.data, np.array([2.0, 2.5, 3.0], dtype=np.float32))\n",
        "\n",
        "    # Test chaining operations (common in ML pipelines)\n",
        "    normalized = (a - 2) / 2  # Center and scale\n",
        "    expected = np.array([-0.5, 0.0, 0.5], dtype=np.float32)\n",
        "    assert np.allclose(normalized.data, expected)\n",
        "\n",
        "    print(\"âœ… Arithmetic operations work correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_arithmetic_operations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zu5Xyaa0iOv",
        "outputId": "a933da4b-7bee-41e8-e8f8-5f159bd98f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Arithmetic Operations...\n",
            "âœ… Arithmetic operations work correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "FjQxxSfdbAFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[2,2], [2,2]])\n",
        "for i in A:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxFUpJoE6iwP",
        "outputId": "507806e8-889a-4adc-9a07-6e8b39c67602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2]\n",
            "[2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dl1kdOT86kOG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}