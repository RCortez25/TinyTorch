{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcsKdgG96J5kTYp74VQq5m"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TaJdgFh4bNJk"
      },
      "outputs": [],
      "source": [
        "#| default_exp core.tensor\n",
        "#| export\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Constants for memory calculations\n",
        "BYTES_PER_FLOAT32 = 4  # Standard float32 size in bytes\n",
        "KB_TO_BYTES = 1024  # Kilobytes to bytes conversion\n",
        "MB_TO_BYTES = 1024 * 1024  # Megabytes to bytes conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor class"
      ],
      "metadata": {
        "id": "TGoGBOE6ar78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "class Tensor:\n",
        "    \"\"\"Tensor - the foundation of machine learning computation.\n",
        "\n",
        "    This class provides the core data structure for all ML operations:\n",
        "    - data: The actual numerical values (NumPy array)\n",
        "    - shape: Dimensions of the tensor\n",
        "    - size: Total number of elements\n",
        "    - dtype: Data type (float32)\n",
        "\n",
        "    All arithmetic, matrix, and shape operations are built on this foundation.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        \"\"\"Create a new tensor from data.\"\"\"\n",
        "        self.data = np.array(data, dtype=np.float32)\n",
        "        self.shape = self.data.shape\n",
        "        self.size = self.data.size\n",
        "        self.dtype = self.data.dtype\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"String representation for debugging\"\n",
        "        return f\"Tensor(data={self.data}, shape={self.shape})\"\n",
        "\n",
        "    def __str__(self):\n",
        "        \"String representation\"\n",
        "        return f\"Tensor({self.data})\"\n",
        "\n",
        "    def numpy(self):\n",
        "        \"Return the NumPy array\"\n",
        "        return self.data\n",
        "\n",
        "    def memory_footprint(self):\n",
        "        \"\"\"Calculate exact memory usage in bytes.\n",
        "\n",
        "        Systems Concept: Understanding memory footprint is fundamental to ML systems.\n",
        "        Before running any operation, engineers should know how much memory it requires.\n",
        "\n",
        "        Returns:\n",
        "            int: Memory usage in bytes (e.g., 1000x1000 float32 = 4MB)\n",
        "        \"\"\"\n",
        "        return self.data.nbytes\n",
        "\n",
        "    def __add__(self, other):\n",
        "        \"\"\"Add two tensors element-wise with broadcasting support.\"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data + other.data)\n",
        "        return self.data + other\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        \"\"\"Subtract two tensors element-wise.\"\"\"\n",
        "\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data - other.data)\n",
        "        return self.data - other\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        \"\"\"Multiply two tensors element-wise (NOT matrix multiplication).\"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data * other.data)\n",
        "        return self.data * other\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        \"\"\"Divide two tensors element-wise.\"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data / other.data)\n",
        "        return Tensor(self.data / other)\n",
        "\n",
        "    def matmul(self, other):\n",
        "        \"\"\"Matrix multiplication of two tensors.\"\"\"\n",
        "        if not isinstance(other, Tensor):\n",
        "            raise TypeError(\"Both elements must be tensors\")\n",
        "        if other.data.ndim == 0:\n",
        "            return Tensor(self * other)\n",
        "        if other.data.ndim == 1:\n",
        "            return Tensor(np.matmul(self.data, other.data))\n",
        "        if not self.shape[-1] == other.shape[-2]:\n",
        "            raise ValueError(f\"Inner dimensions must match. {self.shape[-1]} â‰  {other.shape[-2]}\")\n",
        "        if self.data.shape == (2,2):\n",
        "            lst = []\n",
        "            for i in range(2):\n",
        "                for j in range(2):\n",
        "                    result = np.dot(self.data[i,:],other.data[:,j])\n",
        "                    lst.append(result)\n",
        "            return Tensor(np.array(lst).reshape(2,2))\n",
        "        return Tensor(np.matmul(self.data, other.data))\n",
        "\n",
        "    def __matmul__(self, other):\n",
        "        \"\"\"Enable @ operator for matrix multiplication.\"\"\"\n",
        "        return self.matmul(other)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"Enable indexing and slicing operations on Tensors.\n",
        "\n",
        "        TODO: Implement indexing and slicing that returns a new Tensor.\n",
        "\n",
        "        APPROACH:\n",
        "        1. Use NumPy indexing: self.data[key]\n",
        "        2. If result is not an ndarray, wrap in np.array\n",
        "        3. Return result wrapped in new Tensor\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> t = Tensor([[1, 2, 3], [4, 5, 6]])\n",
        "        >>> row = t[0]  # First row\n",
        "        >>> print(row.data)\n",
        "        [1. 2. 3.]\n",
        "        >>> element = t[0, 1]  # Single element\n",
        "        >>> print(element.data)\n",
        "        2.0\n",
        "\n",
        "        HINT: NumPy's indexing already handles all complex cases (slicing, fancy indexing)\n",
        "        \"\"\"\n",
        "        ### BEGIN SOLUTION\n"
      ],
      "metadata": {
        "id": "i4z_D0m4bXEo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### TESTS\n",
        "matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3\n",
        "vector = Tensor([1, 2, 3])  # 3Ã—1 (conceptually)\n",
        "result = matrix.matmul(vector)\n",
        "result\n",
        "# Expected: [1Ã—1+2Ã—2+3Ã—3, 4Ã—1+5Ã—2+6Ã—3] = [14, 32]\n",
        "# expected = np.array([14, 32], dtype=np.float32)\n",
        "# assert np.array_equal(result.data, expected)\n",
        "# matrix = Tensor([[1, 2], [3, 4]])\n",
        "# vector = Tensor([10, 20])\n",
        "# result = matrix + vector\n",
        "# expected = np.array([[11, 22], [13, 24]], dtype=np.float32)\n",
        "# assert np.array_equal(result.data, expected)\n",
        "# result\n",
        "# matrix.data.ndim\n",
        "# a = Tensor(2)\n",
        "# a.data.ndim\n",
        "# matrix.matmul(a)\n",
        "#################### TESTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_fMzoqa0mG4",
        "outputId": "a93804e6-a375-4c3c-83ff-e158d2408717"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tensor(data=[14. 32.], shape=(2,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit tests"
      ],
      "metadata": {
        "id": "_hhk0dhgax1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_matrix_multiplication():\n",
        "    \"\"\"ðŸ§ª Test matrix multiplication operations.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Matrix Multiplication...\")\n",
        "\n",
        "    # Test 2Ã—2 matrix multiplication (basic case)\n",
        "    a = Tensor([[1, 2], [3, 4]])  # 2Ã—2\n",
        "    b = Tensor([[5, 6], [7, 8]])  # 2Ã—2\n",
        "    result = a.matmul(b)\n",
        "    # Expected: [[1Ã—5+2Ã—7, 1Ã—6+2Ã—8], [3Ã—5+4Ã—7, 3Ã—6+4Ã—8]] = [[19, 22], [43, 50]]\n",
        "    expected = np.array([[19, 22], [43, 50]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test rectangular matrices (common in neural networks)\n",
        "    c = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3 (like batch_size=2, features=3)\n",
        "    d = Tensor([[7, 8], [9, 10], [11, 12]])  # 3Ã—2 (like features=3, outputs=2)\n",
        "    result = c.matmul(d)\n",
        "    # Expected: [[1Ã—7+2Ã—9+3Ã—11, 1Ã—8+2Ã—10+3Ã—12], [4Ã—7+5Ã—9+6Ã—11, 4Ã—8+5Ã—10+6Ã—12]]\n",
        "    expected = np.array([[58, 64], [139, 154]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test matrix-vector multiplication (common in forward pass)\n",
        "    matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3\n",
        "    vector = Tensor([1, 2, 3])  # 3Ã—1 (conceptually)\n",
        "    result = matrix.matmul(vector)\n",
        "    # Expected: [1Ã—1+2Ã—2+3Ã—3, 4Ã—1+5Ã—2+6Ã—3] = [14, 32]\n",
        "    expected = np.array([14, 32], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test shape validation - should raise clear error\n",
        "    try:\n",
        "        incompatible_a = Tensor([[1, 2]])     # 1Ã—2\n",
        "        incompatible_b = Tensor([[1], [2], [3]])  # 3Ã—1\n",
        "        incompatible_a.matmul(incompatible_b)  # 1Ã—2 @ 3Ã—1 should fail (2 â‰  3)\n",
        "        assert False, \"Should have raised ValueError for incompatible shapes\"\n",
        "    except ValueError as e:\n",
        "        assert \"Inner dimensions must match\" in str(e)\n",
        "        assert \"2 â‰  3\" in str(e)  # Should show specific dimensions\n",
        "\n",
        "    print(\"âœ… Matrix multiplication works correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_matrix_multiplication()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOrSZT355FFk",
        "outputId": "155d44a9-1612-4637-9523-47833aa69294"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Matrix Multiplication...\n",
            "âœ… Matrix multiplication works correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_arithmetic_operations():\n",
        "    \"\"\"ðŸ§ª Test arithmetic operations with broadcasting.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Arithmetic Operations...\")\n",
        "\n",
        "    # Test tensor + tensor\n",
        "    a = Tensor([1, 2, 3])\n",
        "    b = Tensor([4, 5, 6])\n",
        "    result = a + b\n",
        "    assert np.array_equal(result.data, np.array([5, 7, 9], dtype=np.float32))\n",
        "\n",
        "    # Test tensor + scalar (very common in ML)\n",
        "    result = a + 10\n",
        "    assert np.array_equal(result.data, np.array([11, 12, 13], dtype=np.float32))\n",
        "\n",
        "    # Test broadcasting with different shapes (matrix + vector)\n",
        "    matrix = Tensor([[1, 2], [3, 4]])\n",
        "    vector = Tensor([10, 20])\n",
        "    result = matrix + vector\n",
        "    expected = np.array([[11, 22], [13, 24]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test subtraction (data centering)\n",
        "    result = b - a\n",
        "    assert np.array_equal(result.data, np.array([3, 3, 3], dtype=np.float32))\n",
        "\n",
        "    # Test multiplication (scaling)\n",
        "    result = a * 2\n",
        "    assert np.array_equal(result.data, np.array([2, 4, 6], dtype=np.float32))\n",
        "\n",
        "    # Test division (normalization)\n",
        "    result = b / 2\n",
        "    assert np.array_equal(result.data, np.array([2.0, 2.5, 3.0], dtype=np.float32))\n",
        "\n",
        "    # Test chaining operations (common in ML pipelines)\n",
        "    normalized = (a - 2) / 2  # Center and scale\n",
        "    expected = np.array([-0.5, 0.0, 0.5], dtype=np.float32)\n",
        "    assert np.allclose(normalized.data, expected)\n",
        "\n",
        "    print(\"âœ… Arithmetic operations work correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_arithmetic_operations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zu5Xyaa0iOv",
        "outputId": "c13f1b0b-cf3a-4c31-ac01-87bee3cdd1e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Arithmetic Operations...\n",
            "âœ… Arithmetic operations work correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "FjQxxSfdbAFC"
      }
    }
  ]
}