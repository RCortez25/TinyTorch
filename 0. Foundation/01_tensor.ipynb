{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5XMZny5XeZ0M3QijAPsel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RCortez25/TinyTorch/blob/main/0.%20Foundation/01_tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "TaJdgFh4bNJk"
      },
      "outputs": [],
      "source": [
        "#| default_exp core.tensor\n",
        "#| export\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Constants for memory calculations\n",
        "BYTES_PER_FLOAT32 = 4  # Standard float32 size in bytes\n",
        "KB_TO_BYTES = 1024  # Kilobytes to bytes conversion\n",
        "MB_TO_BYTES = 1024 * 1024  # Megabytes to bytes conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor class"
      ],
      "metadata": {
        "id": "TGoGBOE6ar78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "class Tensor:\n",
        "    \"\"\"Educational tensor - the foundation of machine learning computation.\n",
        "\n",
        "    This class provides the core data structure for all ML operations:\n",
        "    - data: The actual numerical values (NumPy array)\n",
        "    - shape: Dimensions of the tensor\n",
        "    - size: Total number of elements\n",
        "    - dtype: Data type (float32)\n",
        "\n",
        "    All arithmetic, matrix, and shape operations are built on this foundation.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        \"\"\"Create a new tensor from data.\n",
        "\n",
        "        TODO: Initialize a Tensor by wrapping data in a NumPy array and setting attributes.\n",
        "\n",
        "        APPROACH:\n",
        "        1. Convert data to NumPy array with dtype=float32\n",
        "        2. Store the array as self.data\n",
        "        3. Set self.shape from the array's shape\n",
        "        4. Set self.size from the array's size\n",
        "        5. Set self.dtype from the array's dtype\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> t = Tensor([1, 2, 3])\n",
        "        >>> print(t.shape)\n",
        "        (3,)\n",
        "        >>> print(t.size)\n",
        "        3\n",
        "\n",
        "        HINT: Use np.array(data, dtype=np.float32) to convert data to NumPy array\n",
        "        \"\"\"\n",
        "        self.data = np.array(data, dtype=np.float32)\n",
        "        self.shape = self.data.shape\n",
        "        self.size = self.data.size\n",
        "        self.dtype = self.data.dtype\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"String representation for debugging\"\n",
        "        return f\"Tensor(data={self.data}, shape={self.shape})\"\n",
        "\n",
        "    def __str__(self):\n",
        "        \"String representation\"\n",
        "        return f\"Tensor({self.data})\"\n",
        "\n",
        "    def numpy(self):\n",
        "        \"Return the NumPy array\"\n",
        "        return self.data\n",
        "\n",
        "    def memory_footprint(self):\n",
        "        \"\"\"Calculate exact memory usage in bytes.\n",
        "\n",
        "        Systems Concept: Understanding memory footprint is fundamental to ML systems.\n",
        "        Before running any operation, engineers should know how much memory it requires.\n",
        "\n",
        "        Returns:\n",
        "            int: Memory usage in bytes (e.g., 1000x1000 float32 = 4MB)\n",
        "        \"\"\"\n",
        "        return self.data.nbytes\n",
        "\n",
        "    def __add__(self, other):\n",
        "        \"\"\"Add two tensors element-wise with broadcasting support.\n",
        "\n",
        "        TODO: Implement element-wise addition that works with both Tensors and scalars.\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor (use isinstance)\n",
        "        2. If Tensor: add self.data + other.data\n",
        "        3. If scalar: add self.data + other (broadcasting)\n",
        "        4. Wrap result in new Tensor\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([1, 2, 3])\n",
        "        >>> b = Tensor([4, 5, 6])\n",
        "        >>> c = a + b\n",
        "        >>> print(c.data)\n",
        "        [5. 7. 9.]\n",
        "\n",
        "        HINT: NumPy's + operator handles broadcasting automatically\n",
        "        \"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data + other.data)\n",
        "        return self.data + other\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        \"\"\"Subtract two tensors element-wise.\n",
        "\n",
        "        TODO: Implement element-wise subtraction (same pattern as __add__).\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor\n",
        "        2. If Tensor: subtract self.data - other.data\n",
        "        3. If scalar: subtract self.data - other\n",
        "        4. Return new Tensor with result\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([5, 7, 9])\n",
        "        >>> b = Tensor([1, 2, 3])\n",
        "        >>> c = a - b\n",
        "        >>> print(c.data)\n",
        "        [4. 5. 6.]\n",
        "\n",
        "        HINT: Follow the same pattern as __add__ but with subtraction\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data - other.data)\n",
        "        return self.data - other\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        \"\"\"Multiply two tensors element-wise (NOT matrix multiplication).\n",
        "\n",
        "        TODO: Implement element-wise multiplication (same pattern as __add__).\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor\n",
        "        2. If Tensor: multiply self.data * other.data\n",
        "        3. If scalar: multiply self.data * other\n",
        "        4. Return new Tensor with result\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([1, 2, 3])\n",
        "        >>> b = Tensor([4, 5, 6])\n",
        "        >>> c = a * b\n",
        "        >>> print(c.data)\n",
        "        [ 4. 10. 18.]\n",
        "\n",
        "        HINT: Element-wise multiplication is *, not matrix multiplication (@)\n",
        "        \"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data * other.data)\n",
        "        return self.data * other\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        \"\"\"Divide two tensors element-wise.\n",
        "\n",
        "        TODO: Implement element-wise division (same pattern as __add__).\n",
        "\n",
        "        APPROACH:\n",
        "        1. Check if other is a Tensor\n",
        "        2. If Tensor: divide self.data / other.data\n",
        "        3. If scalar: divide self.data / other\n",
        "        4. Return new Tensor with result\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([4, 6, 8])\n",
        "        >>> b = Tensor([2, 2, 2])\n",
        "        >>> c = a / b\n",
        "        >>> print(c.data)\n",
        "        [2. 3. 4.]\n",
        "\n",
        "        HINT: Division creates float results automatically due to float32 dtype\n",
        "        \"\"\"\n",
        "        if isinstance(other, Tensor):\n",
        "            return Tensor(self.data / other.data)\n",
        "        return Tensor(self.data / other)\n",
        "\n",
        "    def matmul(self, other):\n",
        "        \"\"\"Matrix multiplication of two tensors.\n",
        "\n",
        "        TODO: Implement matrix multiplication with shape validation.\n",
        "\n",
        "        APPROACH:\n",
        "        1. Validate other is a Tensor (raise TypeError if not)\n",
        "        2. Check for scalar cases (0D tensors) - use element-wise multiply\n",
        "        3. For 2D+ matrices: validate inner dimensions match (shape[-1] == shape[-2])\n",
        "        4. For 2D matrices: use explicit nested loops (educational)\n",
        "        5. For batched (3D+): use np.matmul for correctness\n",
        "        6. Return result wrapped in Tensor\n",
        "\n",
        "        EXAMPLE:\n",
        "        >>> a = Tensor([[1, 2], [3, 4]])  # 2Ã—2\n",
        "        >>> b = Tensor([[5, 6], [7, 8]])  # 2Ã—2\n",
        "        >>> c = a.matmul(b)\n",
        "        >>> print(c.data)\n",
        "        [[19. 22.]\n",
        "         [43. 50.]]\n",
        "\n",
        "        HINTS:\n",
        "        - Inner dimensions must match: (M, K) @ (K, N) = (M, N)\n",
        "        - For 2D case: use np.dot(a[i, :], b[:, j]) for each output element\n",
        "        - Raise ValueError with clear message if shapes incompatible\n",
        "        \"\"\"\n",
        "        if not isinstance(other, Tensor):\n",
        "            raise TypeError(\"Both elements must be tensors\")\n",
        "        if other.data.ndim == 0:\n",
        "            return self * other\n",
        "        if other.data.ndim == 1:\n",
        "            return np.matmul(self.data, other.data)\n",
        "        if not self.shape[-1] == other.shape[-2]:\n",
        "            raise ValueError(f\"Inner dimensions must match. {self.shape[-1]} â‰  {other.shape[-2]}\")\n",
        "        if self.data.shape == (2,2):\n",
        "            lst = []\n",
        "            for i in range(2):\n",
        "                for j in range(2):\n",
        "                    result = np.dot(self.data[i,:],b.data[:,j])\n",
        "                    lst.append(result)\n",
        "            return Tensor(np.array(lst).reshape(2,2))\n",
        "        return np.matmul(self.data, other.data)\n"
      ],
      "metadata": {
        "id": "i4z_D0m4bXEo"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### TESTS\n",
        "matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3\n",
        "vector = Tensor([1, 2, 3])  # 3Ã—1 (conceptually)\n",
        "result = matrix.matmul(vector)\n",
        "result\n",
        "# Expected: [1Ã—1+2Ã—2+3Ã—3, 4Ã—1+5Ã—2+6Ã—3] = [14, 32]\n",
        "# expected = np.array([14, 32], dtype=np.float32)\n",
        "# assert np.array_equal(result.data, expected)\n",
        "# matrix = Tensor([[1, 2], [3, 4]])\n",
        "# vector = Tensor([10, 20])\n",
        "# result = matrix + vector\n",
        "# expected = np.array([[11, 22], [13, 24]], dtype=np.float32)\n",
        "# assert np.array_equal(result.data, expected)\n",
        "# result\n",
        "# matrix.data.ndim\n",
        "# a = Tensor(2)\n",
        "# a.data.ndim\n",
        "# matrix.matmul(a)\n",
        "#################### TESTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_fMzoqa0mG4",
        "outputId": "3fb7a1b3-47d3-4531-bbe2-0e2940cfc52b"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14., 32.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit tests"
      ],
      "metadata": {
        "id": "_hhk0dhgax1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_matrix_multiplication():\n",
        "    \"\"\"ðŸ§ª Test matrix multiplication operations.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Matrix Multiplication...\")\n",
        "\n",
        "    # Test 2Ã—2 matrix multiplication (basic case)\n",
        "    a = Tensor([[1, 2], [3, 4]])  # 2Ã—2\n",
        "    b = Tensor([[5, 6], [7, 8]])  # 2Ã—2\n",
        "    result = a.matmul(b)\n",
        "    # Expected: [[1Ã—5+2Ã—7, 1Ã—6+2Ã—8], [3Ã—5+4Ã—7, 3Ã—6+4Ã—8]] = [[19, 22], [43, 50]]\n",
        "    expected = np.array([[19, 22], [43, 50]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test rectangular matrices (common in neural networks)\n",
        "    c = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3 (like batch_size=2, features=3)\n",
        "    d = Tensor([[7, 8], [9, 10], [11, 12]])  # 3Ã—2 (like features=3, outputs=2)\n",
        "    result = c.matmul(d)\n",
        "    # Expected: [[1Ã—7+2Ã—9+3Ã—11, 1Ã—8+2Ã—10+3Ã—12], [4Ã—7+5Ã—9+6Ã—11, 4Ã—8+5Ã—10+6Ã—12]]\n",
        "    expected = np.array([[58, 64], [139, 154]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test matrix-vector multiplication (common in forward pass)\n",
        "    matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3\n",
        "    vector = Tensor([1, 2, 3])  # 3Ã—1 (conceptually)\n",
        "    result = matrix.matmul(vector)\n",
        "    # Expected: [1Ã—1+2Ã—2+3Ã—3, 4Ã—1+5Ã—2+6Ã—3] = [14, 32]\n",
        "    expected = np.array([14, 32], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test shape validation - should raise clear error\n",
        "    try:\n",
        "        incompatible_a = Tensor([[1, 2]])     # 1Ã—2\n",
        "        incompatible_b = Tensor([[1], [2], [3]])  # 3Ã—1\n",
        "        incompatible_a.matmul(incompatible_b)  # 1Ã—2 @ 3Ã—1 should fail (2 â‰  3)\n",
        "        assert False, \"Should have raised ValueError for incompatible shapes\"\n",
        "    except ValueError as e:\n",
        "        assert \"Inner dimensions must match\" in str(e)\n",
        "        assert \"2 â‰  3\" in str(e)  # Should show specific dimensions\n",
        "\n",
        "    print(\"âœ… Matrix multiplication works correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_matrix_multiplication()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOrSZT355FFk",
        "outputId": "57e3bb47-f62a-40d3-8227-70b14d61d479"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Matrix Multiplication...\n",
            "âœ… Matrix multiplication works correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_unit_arithmetic_operations():\n",
        "    \"\"\"ðŸ§ª Test arithmetic operations with broadcasting.\"\"\"\n",
        "    print(\"ðŸ§ª Unit Test: Arithmetic Operations...\")\n",
        "\n",
        "    # Test tensor + tensor\n",
        "    a = Tensor([1, 2, 3])\n",
        "    b = Tensor([4, 5, 6])\n",
        "    result = a + b\n",
        "    assert np.array_equal(result.data, np.array([5, 7, 9], dtype=np.float32))\n",
        "\n",
        "    # Test tensor + scalar (very common in ML)\n",
        "    result = a + 10\n",
        "    assert np.array_equal(result.data, np.array([11, 12, 13], dtype=np.float32))\n",
        "\n",
        "    # Test broadcasting with different shapes (matrix + vector)\n",
        "    matrix = Tensor([[1, 2], [3, 4]])\n",
        "    vector = Tensor([10, 20])\n",
        "    result = matrix + vector\n",
        "    expected = np.array([[11, 22], [13, 24]], dtype=np.float32)\n",
        "    assert np.array_equal(result.data, expected)\n",
        "\n",
        "    # Test subtraction (data centering)\n",
        "    result = b - a\n",
        "    assert np.array_equal(result.data, np.array([3, 3, 3], dtype=np.float32))\n",
        "\n",
        "    # Test multiplication (scaling)\n",
        "    result = a * 2\n",
        "    assert np.array_equal(result.data, np.array([2, 4, 6], dtype=np.float32))\n",
        "\n",
        "    # Test division (normalization)\n",
        "    result = b / 2\n",
        "    assert np.array_equal(result.data, np.array([2.0, 2.5, 3.0], dtype=np.float32))\n",
        "\n",
        "    # Test chaining operations (common in ML pipelines)\n",
        "    normalized = (a - 2) / 2  # Center and scale\n",
        "    expected = np.array([-0.5, 0.0, 0.5], dtype=np.float32)\n",
        "    assert np.allclose(normalized.data, expected)\n",
        "\n",
        "    print(\"âœ… Arithmetic operations work correctly!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_unit_arithmetic_operations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zu5Xyaa0iOv",
        "outputId": "402a5fa7-d3e9-4d23-b0f2-9d7afec0e929"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Unit Test: Arithmetic Operations...\n",
            "âœ… Arithmetic operations work correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "FjQxxSfdbAFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3 (like batch_size=2, features=3)\n",
        "d = Tensor([[7, 8], [9, 10], [11, 12]])  # 3Ã—2 (like features=3, outputs=2)\n",
        "result = c.matmul(d)\n"
      ],
      "metadata": {
        "id": "5bffXsQ8gvBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[2,2], [2,2]])\n",
        "for i in A:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "LxFUpJoE6iwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Tensor([[1, 2], [3, 4]])  # 2Ã—2\n",
        "b = Tensor([[5, 6], [7, 8]])  # 2Ã—2"
      ],
      "metadata": {
        "id": "dl1kdOT86kOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = []\n",
        "d = np.zeros([2,2])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        print(a.data[i,:],b.data[:,j])\n",
        "        print(np.dot(a.data[i,:],b.data[:,j]))\n",
        "        lst.append(np.dot(a.data[i,:],b.data[:,j]))\n",
        "lst = np.array(lst).reshape(2,2)\n",
        "lst\n",
        "# for i in a.data:\n",
        "#     for j in b.data:\n",
        "#         print(a.data[i,:])"
      ],
      "metadata": {
        "id": "_njhHznNdfu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.data.ndim"
      ],
      "metadata": {
        "id": "fsMIaHXycVdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = Tensor([2,3,4])\n",
        "c.shape"
      ],
      "metadata": {
        "id": "HPNud7YTc_s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = Tensor([[1, 2, 3], [4, 5, 6]])  # 2Ã—3\n",
        "vector = Tensor([1, 2, 3])  # 3Ã—1 (conceptually)\n",
        "result = matrix.matmul(vector)\n",
        "result"
      ],
      "metadata": {
        "id": "z75mEgAfjWZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18396411"
      },
      "source": [
        "### Method 1: Using `arr.ndim`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc2a36d0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example 1: A 1D array\n",
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "print(f\"Array 1: {array_1d}\\n  ndim: {array_1d.ndim}\")\n",
        "if array_1d.ndim == 1:\n",
        "    print(\"  This is a 1D array.\\n\")\n",
        "else:\n",
        "    print(\"  This is NOT a 1D array.\\n\")\n",
        "\n",
        "# Example 2: A 2D array\n",
        "array_2d = np.array([[1, 2], [3, 4]])\n",
        "print(f\"Array 2:\\n{array_2d}\\n  ndim: {array_2d.ndim}\")\n",
        "if array_2d.ndim == 1:\n",
        "    print(\"  This is a 1D array.\\n\")\n",
        "else:\n",
        "    print(\"  This is NOT a 1D array.\\n\")\n",
        "\n",
        "# Example 3: A 0D array (scalar)\n",
        "array_0d = np.array(10)\n",
        "print(f\"Array 3: {array_0d}\\n  ndim: {array_0d.ndim}\")\n",
        "if array_0d.ndim == 1:\n",
        "    print(\"  This is a 1D array.\\n\")\n",
        "else:\n",
        "    print(\"  This is NOT a 1D array.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0398f020"
      },
      "source": [
        "### Method 2: Using `arr.shape`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce96a199"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example 1: A 1D array\n",
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "print(f\"Array 1: {array_1d}\\n  shape: {array_1d.shape}\")\n",
        "if len(array_1d.shape) == 1:\n",
        "    print(\"  This is a 1D array.\\n\")\n",
        "else:\n",
        "    print(\"  This is NOT a 1D array.\\n\")\n",
        "\n",
        "# Example 2: A 2D array\n",
        "array_2d = np.array([[1, 2], [3, 4]])\n",
        "print(f\"Array 2:\\n{array_2d}\\n  shape: {array_2d.shape}\")\n",
        "if len(array_2d.shape) == 1:\n",
        "    print(\"  This is a 1D array.\\n\")\n",
        "else:\n",
        "    print(\"  This is NOT a 1D array.\\n\")\n",
        "\n",
        "# Example 3: A 0D array (scalar)\n",
        "array_0d = np.array(10)\n",
        "print(f\"Array 3: {array_0d}\\n  shape: {array_0d.shape}\")\n",
        "if len(array_0d.shape) == 1:\n",
        "    print(\"  This is a 1D array.\\n\")\n",
        "else:\n",
        "    print(\"  This is NOT a 1D array.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a * c"
      ],
      "metadata": {
        "id": "o2QXxR_WdMng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.size"
      ],
      "metadata": {
        "id": "9e7FqnVKcXll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8507ee98",
        "outputId": "cb1ed3c3-4d9a-4a52-92fc-0c23a78d9a24"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a 2D NumPy array (3 rows, 4 columns)\n",
        "my_2d_array = np.array([[1, 2, 3, 4],\n",
        "                        [5, 6, 7, 8],\n",
        "                        [9, 10, 11, 12]])\n",
        "\n",
        "print(\"2D Array:\\n\", my_2d_array)\n",
        "print(\"Shape:\", my_2d_array.shape) # (rows, columns)\n",
        "print(\"Number of dimensions (ndim):\", my_2d_array.ndim)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D Array:\n",
            " [[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n",
            "Shape: (3, 4)\n",
            "Number of dimensions (ndim): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TeCaK93jiar1"
      },
      "execution_count": 102,
      "outputs": []
    }
  ]
}